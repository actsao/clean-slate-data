{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation for the Interactive Analysis Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: DOCUMENTATION/EXPLANATIONS FOR THIS NOTEBOOK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframes for Northwest, Suffolk, and Middlesex\n",
    "nw = pd.read_csv('../data/cleaned/clean_northwestern.csv', encoding='utf8',\n",
    "                    dtype={})\n",
    "sf = pd.read_csv('../data/cleaned/clean_suffolk.csv', encoding='utf8',\n",
    "                    dtype={})\n",
    "ms = pd.read_csv('../data/cleaned/clean_middlesex.csv', encoding='utf8',\n",
    "                    dtype={'Incident_Guilty_or_missing':str}, low_memory=False)\n",
    "pd.set_option(\"display.max.columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Additional Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column: 'Inc_Juvenile', so the information is found under the same column name in all regions\n",
    "ms['Inc_Juvenile'] = ms['JuvenileC']\n",
    "# Suffolk has no juvenile data; all incidents are treated as juvenile\n",
    "sf['Inc_Juvenile'] = True\n",
    "nw['Inc_Juvenile'] = nw['Age at Offense'] < 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column: 'Inc_Felony' (boolean)\n",
    "# This is dummy data; eventually this data will be implemented earlier in the data pipeline\n",
    "np.random.seed(42)\n",
    "for x in [nw, ms, sf]:\n",
    "    x['Inc_Felony'] = (np.random.randint(0,20, x.shape[0]))\n",
    "    x['Inc_Felony'] = x['Inc_Felony'] == 19\n",
    "    \n",
    "nw['Inc_Felony'] = nw.groupby(['Person ID', 'Offense Date'])['Inc_Felony'].transform('min')\n",
    "sf['Inc_Felony'] = sf.groupby(['Person ID', 'Offense Date'])['Inc_Felony'].transform('min')\n",
    "ms['Inc_Felony'] = ms.groupby(['Case Number'])['Inc_Felony'].transform('min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column: 'Inc_Years_Remaining'; the number of years that must still pass before the incident may be eligible\n",
    "# That's 3 years for a misdemeanor, and 7 years for a felony\n",
    "# Note that any incident for which the waiting period has already passed will have a value <= 0\n",
    "for x in [nw, ms, sf]:\n",
    "    #x['Inc_Years_Remaining'] = 0\n",
    "    x.loc[(x['Inc_Felony'] == True),['Inc_Years_Remaining']] = 7 - x['years_since_offense']\n",
    "    x.loc[(x['Inc_Felony'] == False),['Inc_Years_Remaining']] = 3 - x['years_since_offense']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateIncidentCode(row):\n",
    "    # This function returns a string 6 digits long; each digit can be 1 or 0. For each digit position, a 1 indicates:\n",
    "    # First: incident occured at a juvenile age\n",
    "    # Second: all incident offenses are eligible for expungement under 100J\n",
    "    # Third: at least one incident offense is a sex or murder offense\n",
    "    # Fourth: at least one incident offense has a guilty disposition\n",
    "    # Fifth: at least one incident offense lacks all disposition data\n",
    "    # Sixth: not enough years have passed for the incident to be potentially expungeable\n",
    "    \n",
    "    result = list('000000')\n",
    "    if row['Inc_Juvenile']:\n",
    "        result[0] = '1'\n",
    "    if row['Inc_Expungeable_Attempts_Are']:\n",
    "        result[1] = '1'\n",
    "    if row['Inc_Sex_or_Murder']:\n",
    "        result[2] = '1'\n",
    "    if row['Incident_Guilty_or_missing'] == 'True':\n",
    "        result[3] = '1'\n",
    "    if row['Inc_Missing_Any_Dispo']:\n",
    "        result[4] = '1'\n",
    "    if row['Inc_Years_Remaining'] > 0:\n",
    "        result[5] = '1'\n",
    "        \n",
    "    return ''.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column: 'Incident Code'\n",
    "for x in [nw, ms, sf]:\n",
    "    x['Incident Code'] = x.apply(lambda row: generateIncidentCode(row), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Reduce Dataframes Into Single-Column Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   All Incident Codes\n",
      "0      001000010000000000000100000001\n",
      "5                              010100\n",
      "6                              010000\n",
      "7                        010000000100\n",
      "9      010000010000000000000000010101\n",
      "...                               ...\n",
      "33063                          010000\n",
      "33064                          000100\n",
      "33065                          010000\n",
      "33066                    010000010000\n",
      "33068                          000100\n",
      "\n",
      "[19517 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "nw_summary = (nw.groupby(['Person ID', 'Offense Date'])['Incident Code'].first().reset_index())\n",
    "nw_summary['All Incident Codes'] = nw_summary.groupby(['Person ID'])['Incident Code'].transform(lambda y: ''.join(y))\n",
    "nw_summary.drop_duplicates(subset='Person ID', inplace=True)\n",
    "nw_summary.drop(columns=['Person ID', 'Offense Date', 'Incident Code'], inplace=True)\n",
    "print(nw_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       All Incident Codes\n",
      "0                                                  110100\n",
      "1       1100001101001001001001001000001000001000001001...\n",
      "10                   110000110100110100110100100100110011\n",
      "16                                           100100100000\n",
      "18                                           100000100100\n",
      "...                                                   ...\n",
      "147341                                             110000\n",
      "147342                                             100100\n",
      "147343                                             110000\n",
      "147344                                             110010\n",
      "147345                                             110000\n",
      "\n",
      "[90440 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "sf_summary = (sf.groupby(['Person ID', 'Offense Date'])['Incident Code'].first().reset_index())\n",
    "sf_summary['All Incident Codes'] = sf_summary.groupby(['Person ID'])['Incident Code'].transform(lambda y: ''.join(y))\n",
    "sf_summary.drop_duplicates(subset='Person ID', inplace=True)\n",
    "sf_summary.drop(columns=['Person ID', 'Offense Date', 'Incident Code'], inplace=True)\n",
    "print(sf_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       All Incident Codes\n",
      "0                  010100\n",
      "1                  001000\n",
      "2                  010000\n",
      "3                  001000\n",
      "4                  101000\n",
      "...                   ...\n",
      "163706             010001\n",
      "163707             010001\n",
      "163708             010001\n",
      "163709             010001\n",
      "163710             001000\n",
      "\n",
      "[163711 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "ms_summary = (ms.groupby(['Case Number', 'Offense Date'])['Incident Code'].first().reset_index())\n",
    "ms_summary['All Incident Codes'] = ms_summary.groupby(['Case Number'])['Incident Code'].transform(lambda y: ''.join(y))\n",
    "ms_summary.drop_duplicates(subset='Case Number', inplace=True)\n",
    "ms_summary.drop(columns=['Case Number', 'Offense Date', 'Incident Code'], inplace=True)\n",
    "print(ms_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Answers to questions provided by CFJJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determineEligibility(row, categories):\n",
    "    categoryList = copy.deepcopy(categories)\n",
    "    incidentString = row['All Incident Codes']\n",
    "    incidents = re.findall('......', incidentString)\n",
    "    eligibleToday = True\n",
    "    missingDispo = False\n",
    "    categoryFound = False\n",
    "    \n",
    "    for incident in incidents:\n",
    "        if incident[-1] == '1':\n",
    "            eligibleToday = False\n",
    "        if incident[-2] == '1':\n",
    "            missingDispo = True\n",
    "        \n",
    "        for category in categoryList:\n",
    "            categoryRegex = re.compile(category[1])\n",
    "            if categoryRegex.match(incident):\n",
    "                categoryFound = True\n",
    "                # The focused incident matches the focused category; decrement the category allotment\n",
    "                category[0] = category[0] - 1\n",
    "                if category[0] < 0:\n",
    "                    # If any category exceeds its allotment, this individual is never eligible\n",
    "                    return 0\n",
    "        # If the incident does not belong to any of the given categories, this individual is never eligible\n",
    "        if not categoryFound:\n",
    "            return 0\n",
    "        categoryFound = False\n",
    "    # If this point is reached, the individual is eligible, but may still need to wait for the 3 or 7 years to pass\n",
    "    if eligibleToday and not missingDispo:\n",
    "        return 1\n",
    "    elif eligibleToday and missingDispo:\n",
    "        return 2\n",
    "    elif not eligibleToday and not missingDispo:\n",
    "        return 3\n",
    "    elif not eligibleToday and missingDispo:\n",
    "        return 4\n",
    "    \n",
    "    # This point shouldn't ever be reachable\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printAnswers(categories, region):\n",
    "    if region == 'nw':\n",
    "        regionName = 'Northwest'\n",
    "        df = nw_summary.copy()\n",
    "        unit = 'individuals'\n",
    "    elif region == 'sf':\n",
    "        regionName = 'Suffolk'\n",
    "        df = sf_summary.copy()\n",
    "        unit = 'individuals'\n",
    "    elif region == 'ms':\n",
    "        regionName = 'Middlesex'\n",
    "        df = ms_summary.copy()\n",
    "        unit = 'cases'\n",
    "    else:\n",
    "        print('Invalid region provided')\n",
    "        return\n",
    "    \n",
    "    df['Result'] = df.apply(lambda row: determineEligibility(row, categories), axis=1)\n",
    "    \n",
    "    neverEligible = (df['Result'].values == 0).sum()\n",
    "    eligibleNow = (df['Result'].values == 1).sum()\n",
    "    eligibleNowIncomplete = (df['Result'].values == 2).sum()\n",
    "    eligibleLater = (df['Result'].values == 3).sum()\n",
    "    eligibleLaterIncomplete = (df['Result'].values == 4).sum()\n",
    "    \n",
    "    print(regionName)\n",
    "    print(eligibleNow + eligibleNowIncomplete, unit, 'are eligible today.', eligibleNowIncomplete, 'of them have incomplete disposition data.')\n",
    "    print('An additional', eligibleLater + eligibleLaterIncomplete, unit, 'will become eligible after their waiting period has ended.', eligibleLaterIncomplete, 'of them have incomplete disposition data.')\n",
    "    print(neverEligible, unit, 'will never be eligible.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answerQuestion(categories):\n",
    "    printAnswers(categories, 'nw')\n",
    "    printAnswers(categories, 'sf')\n",
    "    printAnswers(categories, 'ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Northwest\n",
      "980 individuals are eligible today. 34 of them have incomplete disposition data.\n",
      "An additional 386 individuals will become eligible after their waiting period has ended. 19 of them have incomplete disposition data.\n",
      "18151 individuals will never be eligible.\n",
      "\n",
      "Suffolk\n",
      "40728 individuals are eligible today. 5859 of them have incomplete disposition data.\n",
      "An additional 9168 individuals will become eligible after their waiting period has ended. 3263 of them have incomplete disposition data.\n",
      "40544 individuals will never be eligible.\n",
      "\n",
      "Middlesex\n",
      "2443 cases are eligible today. 0 of them have incomplete disposition data.\n",
      "An additional 767 cases will become eligible after their waiting period has ended. 0 of them have incomplete disposition data.\n",
      "160501 cases will never be eligible.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "answerQuestion([[2, '11.1'], [2, '11.0']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Northwest\n",
      "1510 individuals are eligible today. 47 of them have incomplete disposition data.\n",
      "An additional 610 individuals will become eligible after their waiting period has ended. 30 of them have incomplete disposition data.\n",
      "17397 individuals will never be eligible.\n",
      "\n",
      "Suffolk\n",
      "62112 individuals are eligible today. 7878 of them have incomplete disposition data.\n",
      "An additional 15376 individuals will become eligible after their waiting period has ended. 6406 of them have incomplete disposition data.\n",
      "12952 individuals will never be eligible.\n",
      "\n",
      "Middlesex\n",
      "4216 cases are eligible today. 0 of them have incomplete disposition data.\n",
      "An additional 1466 cases will become eligible after their waiting period has ended. 0 of them have incomplete disposition data.\n",
      "158029 cases will never be eligible.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "answerQuestion([[2, '1.01'], [2, '1.00']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Northwest\n",
      "1357 individuals are eligible today. 46 of them have incomplete disposition data.\n",
      "An additional 567 individuals will become eligible after their waiting period has ended. 35 of them have incomplete disposition data.\n",
      "17593 individuals will never be eligible.\n",
      "\n",
      "Suffolk\n",
      "62486 individuals are eligible today. 8898 of them have incomplete disposition data.\n",
      "An additional 17184 individuals will become eligible after their waiting period has ended. 7843 of them have incomplete disposition data.\n",
      "10770 individuals will never be eligible.\n",
      "\n",
      "Middlesex\n",
      "4111 cases are eligible today. 0 of them have incomplete disposition data.\n",
      "An additional 1443 cases will become eligible after their waiting period has ended. 0 of them have incomplete disposition data.\n",
      "158157 cases will never be eligible.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "answerQuestion([[0, '10.1'], [4, '1...']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Output Summary Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the summary dataframes as csv files, overwriting them in the cleaned data folder\n",
    "nw_file = nw_summary.to_csv('../data/cleaned/interactive_northwestern.csv', index=False)\n",
    "ms_file = ms_summary.to_csv('../data/cleaned/interactive_middlesex.csv', index=False)\n",
    "sf_file = sf_summary.to_csv('../data/cleaned/interactive_suffolk.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
